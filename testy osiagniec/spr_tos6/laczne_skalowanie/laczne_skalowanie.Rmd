---
title: "Łączne skalowanie TOS6 i sprawdzianu"
author: "Michał Modzelewski"
date: "`r Sys.Date()`"
output:
  pdf_document:
    highlight: tango
    toc: yes
lang: polish
---

# Wprowadzenie

```{r}
load("data/tos6.RData")

# ustawienie kolorów do wykresów
kolory = palette()
kolory[c(5, 7:8)] = c("cyan3", "darkorange", "dimgrey")
palette(kolory)
```

## Wykorzystane pakiety i funkcje

```{r, message=FALSE}
# devtools::install_github(repo = "mr-majkel/majkTools")
library(majkTools)

# devtools::install_github(repo = "mr-majkel/TAM")
library(TAM, quietly = TRUE)
library(ggplot2)

# funkcja do zakrąglania kolumn liczbowych w data.frame
round_df = function(df, ...) {
  col_class = sapply(df, class)
  col_num = names(grep("numeric", col_class, value = TRUE))
  df[, col_num] = round(df[, col_num], ...)
  df
}

# funckja do wypluwania tabelek z ktt
print_ctt = function(ctt_df, item, group = 1) {
  ctt_col = grep("item$|group|PV|N|Categ|Freq", names(ctt_df))
  ctt_df[(ctt_df$item == item) & (ctt_df$group == group), ctt_col]
}

# funkcja do rysowania boxplotów dla miar dopasowania
fitplot = function(modfit_df, low_fit = 0.8, high_fit = 1.2, ylim = NULL,
                   lab_size = 4) {
  mod_md =  reshape2::melt(modfit_df, "parameter")
  fit_stat = mod_md[grep("fit$", mod_md$variable), ]
  
  boxy = ggplot(fit_stat, aes(x = variable, y = value))
  
  if(!is.null(ylim)) {
    boxy = boxy + ylim(ylim[1], ylim[2])  
  }
  
  high_items = fit_stat[fit_stat$value > high_fit, ]
  low_items = fit_stat[fit_stat$value < low_fit, ]
  
  boxy = boxy + geom_boxplot()
  
  if(nrow(high_items) > 0) {
  boxy = boxy + geom_point(data = high_items) +
    geom_text(aes(label = parameter), data = high_items, hjust = -0.1,
              size = lab_size)
  }
  if(nrow(low_items) > 0) {
  boxy = boxy + geom_point(data = low_items) +
    geom_text(aes(label = parameter), data = low_items, hjust = -0.1,
              size = lab_size)
  }

  boxy = boxy + geom_hline(yintercept = c(low_fit, high_fit),
                           linetype = 2)
  
  boxy
}

# prosta funkcja do rekodowania "zwrotnego"
# funkcja niepodmienia eNek w zadaniach, które nie występują w bazie
# nierekodowanej (zostawia je jak są), dlatego warto rozpłciowić zadania w bazie
# nierekodowanej w taki sam sposób, jak w rekodowanej.

recode_back = function(df_r, df, item = "^[KC]", code = "N") {
  zad_df_r = df_r[, grep(item, names(df_r))]
  zad_df = df[, grep(item, names(df))]
  
  zad_df_r2 = as.data.frame(lapply(names(zad_df_r), function(nm) {
    if(nm %in% names(zad_df)) {
      zad_df_r[which(zad_df[, nm] == code), nm] = 0      
    }
    zad_df_r[, nm]
    
  }), stringsAsFactors = FALSE)
  
  df_r[, grep(item, names(df_r))] = zad_df_r2
  df_r
}

```

# Świadomość językowa

## Model rozpoznawczy

W skalowaniu wykorzystano ostateczny model ze skalowania TOS6 oraz dwa zrekdowane zadania ze sprawdzianu. Rekomendacje ze skalowania TOS6 sprowadzały się do usunięcia dwóch zadań: SA\_2 oraz SA\_24. Dodatkowo w zadaniu KSA\_18 skrócono skalę oceny (kat. 2 została połączona z 1).

Ze sprawdzianu wykorzystano dwa zadania: s\_25 oraz s\_26. W analizie dla tych zadań wykorzystano sumy punktów za wszystkie kryteria oceny.

```{r, cache = TRUE}
mod0 = tam.mml(sj_r[, it_sj], irtmodel = "PCM",
               formulaY = ~ kobieta, dataY = sj_r[, "kobieta", drop = FALSE],
               control = list(increment.factor = 1.01,
                              progress = FALSE))

```

### Dopasowanie

```{r, results = "hide"}
# dopasowanie zadań
fit0 = tam.fit(mod0)$itemfit

# scalenie oszacowań parametrów i dopasowania
mod0$xsi$parameter = rownames(mod0$xsi)
mod0_fit = merge(mod0$xsi, fit0)
```

Poniżej znajdują się oszacowane parametry zadań oraz miary dopasowania.

```{r}
round_df(mod0_fit[, grep("param|xsi|fit$", names(mod0_fit))], 3)
```

Poniżej znajduje się wykres z miarami dopasowania dla zadań.

```{r, fig.keep = 'last'}
fitplot(mod0_fit)
```

Zadanie SB\_23 znajduje się na dolnej granicy (0,8) dopasowania do modelu mierzonego statystyką *outfit*. Dla tej samej miary dopasowania, górną granicę (1,2) przekraczają wszystkie kategorie dla zadania s\_26. Zadanie SB\_23 wykazywało nieco wyższą niż przewidywana dyksryminację również w trakcie skalowania samego TOS6. Nie stanowi to jednak zbytniego obciążenia wyników pomiaru. 

Zadanie s\_26 wymaga jednak większej uwagi. Poniżej znajduje się wykres z krzywymi charakterystycznymi dla tego zadania. Na wykresie umieszczone zostały także obserwowane odsetki dla wszystkich kategorii odpowiedzi dla 8 równolicznych grup wyników.

```{r, results = 'hide', fig.keep = "last", dev.args = list(pointsize = 8)}
plot(mod0, grep("s_26r", mod0$item$item), ngroups = 8,
     type = "items", export = FALSE, package = "graphics")
```

Najbardziej odstającymi kategoriami punktowymi dla zadania s\_26 są kategorie 1 i 2. Wykazują się one zdecydowanie mniejszą zmiennością niż przewiduje to model. 

## Model ze skrócona skalą oceny opowiadania

Po wielu analizach na potrzeby wyliczania wyników przyjęto następujące rozwiązanie: dla kryteriów ocenianych na dłuższych niż zero-jedynkowych skalach, tj. s\_26\_1 ("pisze opowiadanie na zadany temat"; maks. 3 pkt.) oraz s\_26\_3 ("pisze poprawnie pod względem językowym"; maks. 2 pkt.), przyznano po jednym punkcie tylko tym uczniom, którzy zdobyli maksymalną liczbę punktów w danym kryterium.

```{r}
# rekodowanie na 0-1
sj_r$s_26_1r = car::recode(sj_r$s_26_1,
                      "1 = 0; 2 = 0; 3 = 1")
sj_r$s_26_3r = car::recode(sj_r$s_26_3,
                      "1 = 0; 2 = 1")
sj_r$s_26rr = sj_r$s_26_1r + 
              sj_r$s_26_2 + 
              sj_r$s_26_3r + 
              sj_r$s_26_4 +
              sj_r$s_26_5

```

Następnie policzono parametry zadań dla tak zmodyfikowanego modelu.

```{r}
it_sj1 = it_sj
it_sj1[grep("s_26r", it_sj)] = "s_26rr"
mod1 = tam.mml(sj_r[, it_sj1], irtmodel = "PCM",
               formulaY = ~ kobieta, dataY = sj_r[, "kobieta", drop = FALSE],
               control = list(increment.factor = 1.01,
                              progress = FALSE))
```

Poniżej znajdują się parametry zadań wraz z miarami dopasowania.

```{r, results = "hide"}
# dopasowanie zadań
fit1 = tam.fit(mod1)$itemfit

# scalenie oszacowań parametrów i dopasowania
mod1$xsi$parameter = rownames(mod1$xsi)
mod1_fit = merge(mod1$xsi, fit1)
round_df(mod0_fit[, grep("param|xsi|fit$", names(mod0_fit))], 3)
```

Wykres dla miar dopasowania.

```{r, fig.keep = 'last'}
fitplot(mod1_fit)
```

Wykres dla zadania s\_26 (skala skrócona).

```{r, results = "hide", fig.keep = "last", dev.args = list(pointsize = 8)}
plot(mod1, grep("s_26rr", mod1$item$item), ngroups = 7,
     type = "items", export = FALSE, package = "graphics")
```

Choć kategoria 4 wciąż wykazuje lekkie niedopasowanie, to postanowiono pozostawić zadanie s\_26 na tak zmodyfikowanej skali.

## Analiza DIF na płeć

W następnym kroku sprawdzono zadania pod kątem zróżnicowanego funkcjonowania zadań ze względu na płeć.

```{r}
mod2 = tam.mml.mfr(sj_r[, it_sj1],
      formulaA = ~ item + item:step + kobieta + kobieta:item + kobieta:item:step,
      facets = sj_r[, "kobieta", drop = FALSE],
      control = list(increment.factor = 1.03,
                     fac.oldxsi = 0.05,
                     progress = FALSE))
```

Parametry, które wykazują DIF na płeć (bezwzględna różnica w trudności > 0.4; kobieta0 = chłopiec).

```{r}
dif_params = grepl(":kobieta", rownames(mod2$xsi)) & mod2$xsi$xsi != 99
round_df(mod2$xsi[dif_params & abs(mod2$xsi$xsi) > 0.2 , ], 3)
```

Tylko zadania, które były już analizowane na etapie oddzielnego skalowania TOS6 wykazują symptomy zróżnicowanego funkcjonowania (na prawie identycznym poziomie). W związku z tym, do wyliczenia wyników uczniów wykorzystano model ze zrekodowanym zadaniem s\_26.

## Wyliczenie wyników uczniów

Wyliczanie wyników oodbywalo sie w kilku krokach.

1. Wyekstrahowanie parametrów zadań z modelu ostatecznego.

```{r} 
xsi_fixed_sj = cbind(1:length(mod1$xsi$xsi),
                     mod1$xsi$xsi)
```

2. Przekodowanie zadań "nie-zdążonych" (*not reached*) na odpowiedzi błędne.

```{r}
sj_r2 = recode_back(sj_r, sj, item = "^[KS]")
sj_r2[sj_r2 == "N"] = 0
```

3. Policzenie średnich klasowych na podstawie oszacowań EAP z modelu z regresją latentną na płeć i z parametrami zadań z modelu ostatecznego.

```{r}
mod_mean = tam.mml(sj_r2[, it_sj1], xsi.fixed = xsi_fixed_sj,
                   formulaY = ~ kobieta, dataY = sj_r2[, "kobieta", drop = FALSE],
                   control = list(increment.factor = 1.01,
                                  progress = FALSE))

# dołączenie oszacowań do uczniów z informacją o klasie i szkole
osz_ucz = data.frame(sj_r2[, grep("ID_ucz|ID_szk|oddz_6|kobieta",
                                        names(sj_r2))],
                     wyn = mod_mean$person$EAP) 
# policzenie średniej dla klas
osz_kl_mn = plyr::ddply(osz_ucz, c("ID_szk", "oddz_6"),
                         plyr::summarize, srednia_kl = mean(wyn))
# dodanie średniej do zbioru danych
osz_ucz2 = merge(osz_ucz, osz_kl_mn, all.x = TRUE)
```

4. Policzenie wyników (EAP oraz 5 PV) w modelu z regresją latentną na płeć i średnią klasową oraz z parametrami zadań z modelu ostatecznego.

```{r}
mod_ost_mn = tam.mml(sj_r2[, it_sj1], xsi.fixed = xsi_fixed_sj,
                     formulaY = ~ kobieta + srednia_kl,
                     dataY = osz_ucz2[match(osz_ucz2$ID_ucz, sj_r2$ID_ucz), ],
                     pid = sj_r2$ID_ucz,
                     control = list(increment.factor = 1.01,
                                    progress = FALSE))

# policzenie 5 PV
pv_ucz = tam.pv(mod_ost_mn, 5)$pv

# dołączenie PV do wyników EAP i bł.st.
wyn_ucz = merge(mod_ost_mn$person, pv_ucz, all.x = TRUE)
wyn_ucz = wyn_ucz[, -grep("case|pweight", names(wyn_ucz))]

# zmiana nazw zmiennych: EAPy
zmod_EAP = paste0(names(wyn_ucz)[grep("EAP", names(wyn_ucz))], "_sj")
names(wyn_ucz)[grep("EAP", names(wyn_ucz))] = zmod_EAP

# zmiana nazw zmiennych: PV
zmod_PV = gsub(".Dim1", "_sj", names(wyn_ucz)[grep("PV", names(wyn_ucz))])
names(wyn_ucz)[grep("PV", names(wyn_ucz))] = zmod_PV
```

Zapisanie zbioru.

```{r, eval = FALSE}
write.csv2(wyn_ucz, "data/TOS6_Spr_wyniki_sj.csv", row.names = FALSE)
```

# Matematyka

## Model rozpoznawczy

W skalowaniu wykorzystano ostateczny model ze skalowania TOS6 oraz 13 zrekodowanych zadań ze sprawdzianu. Rekomendacje ze skalowania TOS6 sprowadzały się do usunięcia zadania MB\_25. Dodatkowo dla zadania MA\_7 wyliczany jest oddzielny parametr trudności dla chłopców i dziewcząt.

```{r, cache = TRUE}
mat_mod0 = tam.mml(mat_r[, it_mat], irtmodel = "PCM",
                   formulaY = ~ kobieta,
                   dataY = mat_r[, "kobieta", drop = FALSE],
                   control = list(increment.factor = 1.01,
                                  progress = FALSE))
```

### Dopasowanie modelu

```{r, results = "hide"}
# dopasowanie zadań
mat_fit0 = tam.fit(mat_mod0)$itemfit

# scalenie oszacowań parametrów i dopasowania
mat_mod0$xsi$parameter = rownames(mat_mod0$xsi)
mat_mod0_fit = merge(mat_mod0$xsi, mat_fit0)
```

Poniżej znajdują się oszacowane parametry zadań oraz miary dopasowania.

```{r}
round_df(mat_mod0_fit[, grep("param|xsi|fit$", names(mat_mod0_fit))], 3)
```

Wykres dla miar dopasowania.

```{r, fig.keep = 'last'}
fitplot(mat_mod0_fit)
```

Zadanie MA\_20 miało trochę niższą od przewidywanej dyskryminację już na etapie oddzielnego skalowania TOS6. Spośród sprawdzianowych zadań matematycznych dwa są potencjalnie problematyczne.

Dla zadania s\_22, wszystkie kategorie punktowe wykazują niedopasowanie. Zadanie s\_18 z kolei ma wyższą od przewidywanej dyskryminację. Przyjrzyjmy się krzywym charakterystycznym dla tych zadań.

```{r, results = "hide", dev.args = list(pointsize = 8)}
plot(mat_mod0, grep("s_18|s_22", mat_mod0$item$item), ngroups = 7,
     type = "items", export = FALSE, package = "graphics")
```

Wyższa dyskryminacja dla zadania s\_18 może być symptomem złamania założenia o lokalnej niezależności wynikającym z faktu, że zadania s\_17-s\_20 odwołują się do tego samego trzonu (tesktu i tabeli). W kolejnym kroku dopasowano model, w którym zamiast wyników dla poszczególnych zadań wykorzystano sumę punktów.

## Model z sumą dla zadań s\_17-s\_20

```{r}
mat_r$s_17_20r = rowSums(mat_r[, grep("s_1[789]|s_20", names(mat_r))])

# wskazanie zadań do skalowania
it_mat1 = c(it_mat[-grep("s_1[789]|s_20", it_mat)], "s_17_20r")
```

```{r}
mat_mod1 = tam.mml(mat_r[, it_mat1], irtmodel = "PCM",
                   formulaY = ~ kobieta,
                   dataY = mat_r[, "kobieta", drop = FALSE],
                   control = list(increment.factor = 1.01,
                                  progress = FALSE))

```

### Dopasowanie modelu

```{r, results = "hide"}
# dopasowanie zadań
mat_fit1 = tam.fit(mat_mod1)$itemfit

# scalenie oszacowań parametrów i dopasowania
mat_mod1$xsi$parameter = rownames(mat_mod1$xsi)
mat_mod1_fit = merge(mat_mod1$xsi, mat_fit1)
```

Poniżej znajdują się oszacowane parametry zadań oraz miary dopasowania.

```{r}
round_df(mat_mod1_fit[, grep("param|xsi|fit$", names(mat_mod1_fit))], 3)
```

Wykres dla miar dopasowania.

```{r, fig.keep = 'last'}
fitplot(mat_mod1_fit)
```

```{r, results = "hide", dev.args = list(pointsize = 8)}
plot(mat_mod1, grep("s_17", mat_mod1$item$item), ngroups = 7,
     type = "items", export = FALSE, package = "graphics")
```

Suma dla zadań s\_17-s\_20 funkcjonuje odrobinę lepiej niż poszczególne zadania indywidualnie. Kategoria 1 wykazuje jednk podobne niedopasowanie co zadanie s\_18. W związku jednak z faktem, że wspólny trzon dla tych czterech zadań może stanowić problem dla założenia o lokalnej niezależności, a także, że w wyniku połączenia tych zadań skala wyników nie zmieniła się, do dalszych analiz wykorzystano taką wlaśnie skalę.

## Model ze skróconą skalą zadania s\_22

W zadaniu s\_22 mamy do czynienia z kilkoma problemami. Po pierwsze dwie kategorie punktowe prawie nie występują - bardzo niewielu uczniów otrzymało za to zadanie 1 lub 3 punkty. Po drugie, krzywa empiryczna dla kategorii 4 w okolicy 0,5 logita załamuje się i rośnie mniej dynamicznie niż przewiduje to model. Załamanie to powiązane jest z większym niż przewidywanym odsetkiem uczniów o wysokim poziomie umiejętności, którzy otrzymują dwa punkty za to zadanie. Dodatkowo, właśnie w tym zakresie skali umiejętności (0,5-1 logit) ma swoje niewysokie maksimum krzywa empiryczna dla kategorii 3 punkty. W związku z dość dużym niedopasowaniem zadania do modelu Rascha, podjęto próbę skrócenia skali z pięciokategorialnej do trójkategorialnej, próbując jednocześnie zoptymalizować dopasowanie dla nowych kategorii punktowych.

Skalę skrócono poprzez złączenie kategorii 1 i 2 oraz 3 i 4.

```{r}
# zrekdowanie zadania s_22
mat_r$s_22r = car::recode(mat_r$s_22, "2 = 1; 3 = 2; 4 = 2")
# zredefiniowanie zadań do skalowania
it_mat2 = c(it_mat1[-grep("s_22", it_mat1)], "s_22r")

mat_mod2 = tam.mml(mat_r[, it_mat2], irtmodel = "PCM",
                   formulaY = ~ kobieta,
                   dataY = mat_r[, "kobieta", drop = FALSE],
                   control = list(increment.factor = 1.01,
                                  progress = TRUE))
```

### Dopasowanie modelu

```{r, results = "hide"}
# dopasowanie zadań
mat_fit2 = tam.fit(mat_mod2)$itemfit

# scalenie oszacowań parametrów i dopasowania
mat_mod2$xsi$parameter = rownames(mat_mod2$xsi)
mat_mod2_fit = merge(mat_mod2$xsi, mat_fit2)
```

Poniżej znajdują się oszacowane parametry zadań oraz miary dopasowania.

```{r}
round_df(mat_mod2_fit[, grep("param|xsi|fit$", names(mat_mod2_fit))], 3)
```

Wykres dla miar dopasowania.

```{r, fig.keep = 'last'}
fitplot(mat_mod2_fit)
```

```{r, results = "hide", dev.args = list(pointsize = 8)}
plot(mat_mod2, grep("s_22", mat_mod2$item$item), ngroups = 7,
     type = "items", export = FALSE, package = "graphics")
```

Tak zmodyfikowana skala oceny zadania funkcjonuje lepiej niż oryginalna. Jedynie kategoria 0 oraz 1 w zakresie niższych wyników wykazują trochę wyższą niż przewidywana dyskryminację. Dla rozwiązania tego problemu przetestowano również model, w którym oryginalna kategoria 1 była połączona z kategorią 0. Niestety nie poprawiło to tego aspektu zadania. Na potrzeby dalszych analiz zadanie s\_22, analizowane będzie na skróconej skali.

## Analiza DIF na płeć

W następnym kroku sprawdzono zadania pod kątem zróżnicowanego funkcjonowania zadań ze względu na płeć.

```{r}
mat_mod3 = tam.mml.mfr(mat_r[, it_mat2],
      formulaA = ~ item + item:step + kobieta + kobieta:item + kobieta:item:step,
      facets = mat_r[, "kobieta", drop = FALSE],
      control = list(increment.factor = 1.03,
                     fac.oldxsi = 0.06,
                     progress = TRUE))
```

Parametry, które wykazują DIF na płeć (bezwzględna różnica w trudności > 0.4; kobieta0 = chłopiec).

```{r}
dif_params = grepl(":kobieta", rownames(mat_mod3$xsi)) & mat_mod3$xsi$xsi < 98
round_df(mat_mod3$xsi[dif_params & abs(mat_mod3$xsi$xsi) > 0.2 , ], 3)
```

Poza zadaniami TOS6, które wykazywały wcześniej symptomy zróznicowanego funkcjonowania, pojawia się jedno zadanie ze sprawdzianu, s\_11. Zadanie to dotyczy wyznaczania wagi zawartości pojemnika, uwzględniwszy wagę samego pojemnika. Okazuje się, że zadanie to jest łatwiejsze dla chłopców niż dla dziewczynek. Spójrzmy na odsetki poszczególnych odpowiedzi udzielanych przez uczniów w podziale na płeć.

```{r}
mat_mod3_pv = tam.pv(mat_mod3)$pv
mat_ctt3 = tam.ctt(mat[, it_mat], pvscores = mat_mod3_pv[, -1],
                   group = mat$kobieta)
# chłopcy
print_ctt(mat_ctt3, "s_11", group = 0)
# dziewczynki
print_ctt(mat_ctt3, "s_11", group = 1)

# chłopcy
plotctt(mat[mat$kobieta == 0, "s_11", drop = FALSE],
        theta = mat_mod3_pv[mat$kobieta == 0, 2],
        Ncuts = 7)
# dziewczynki
plotctt(mat[mat$kobieta == 1, "s_11", drop = FALSE],
        theta = mat_mod3_pv[mat$kobieta == 1, 2],
        Ncuts = 7)
```

Analiza treściowa nie pozwoliła na stwierdzenie specyficznego dla płci źródła przewagi chłopców w zadaniu s\_11. W związku z tym zadanie pozostawiono bez zmian.

Po analizie zróżnicowanego funkcjonowania zadania ze względu na płeć, przystąpiono do wyliczania wyników uczniów.

## Wyliczenie wyników uczniów

Wyliczanie wyników oodbywalo sie w kilku krokach.

1. Wyekstrahowanie parametrów zadań z modelu ostatecznego.

```{r} 
xsi_fixed_mat = cbind(1:length(mat_mod2$xsi$xsi),
                     mat_mod2$xsi$xsi)
```

2. Przekodowanie zadań "nie-zdążonych" (*not reached*) na odpowiedzi błędne.

```{r}
mat_r2 = recode_back(mat_r, mat, item = "^[KM]")
mat_r2[mat_r2 == "N"] = 0
```

3. Policzenie średnich klasowych na podstawie oszacowań EAP z modelu z regrematą latentną na płeć i z parametrami zadań z modelu ostatecznego.

```{r}
mod_mean = tam.mml(mat_r2[, it_mat1], xsi.fixed = xsi_fixed_mat,
                   formulaY = ~ kobieta, dataY = mat_r2[, "kobieta", drop = FALSE],
                   control = list(increment.factor = 1.01,
                                  progress = FALSE))

# dołączenie oszacowań do uczniów z informacją o klasie i szkole
osz_ucz = data.frame(mat_r2[, grep("ID_ucz|ID_szk|oddz_6|kobieta",
                                        names(mat_r2))],
                     wyn = mod_mean$person$EAP) 
# policzenie średniej dla klas
osz_kl_mn = plyr::ddply(osz_ucz, c("ID_szk", "oddz_6"),
                         plyr::summarize, srednia_kl = mean(wyn))
# dodanie średniej do zbioru danych
osz_ucz2 = merge(osz_ucz, osz_kl_mn, all.x = TRUE)
```

4. Policzenie wyników (EAP oraz 5 PV) w modelu z regrematą latentną na płeć i średnią klasową oraz z parametrami zadań z modelu ostatecznego.

```{r}
mod_ost_mn = tam.mml(mat_r2[, it_mat1], xsi.fixed = xsi_fixed_mat,
                     formulaY = ~ kobieta + srednia_kl,
                     dataY = osz_ucz2[match(osz_ucz2$ID_ucz, mat_r2$ID_ucz), ],
                     pid = mat_r2$ID_ucz,
                     control = list(increment.factor = 1.01,
                                    progress = FALSE))

# policzenie 5 PV
pv_ucz = tam.pv(mod_ost_mn, 5)$pv

# dołączenie PV do wyników EAP i bł.st.
wyn_ucz = merge(mod_ost_mn$person, pv_ucz, all.x = TRUE)
wyn_ucz = wyn_ucz[, -grep("case|pweight", names(wyn_ucz))]

# zmiana nazw zmiennych: EAPy
zmod_EAP = paste0(names(wyn_ucz)[grep("EAP", names(wyn_ucz))], "_mat")
names(wyn_ucz)[grep("EAP", names(wyn_ucz))] = zmod_EAP

# zmiana nazw zmiennych: PV
zmod_PV = gsub(".Dim1", "_mat", names(wyn_ucz)[grep("PV", names(wyn_ucz))])
names(wyn_ucz)[grep("PV", names(wyn_ucz))] = zmod_PV
```

Zapisanie zbioru.

```{r, eval = FALSE}
write.csv2(wyn_ucz, "data/TOS6_Spr_wyniki_mat.csv", row.names = FALSE)
```


# Czytanie

## Model rozpoznawczy

W skalowaniu wykorzystano ostateczny model ze skalowania TOS6 oraz 10 zrekodowanych zadań ze sprawdzianu. Rekomendacje ze skalowania TOS6 sprowadzały się do usunięcia zadania KCA\_1. Dodatkowo dla zadania MA\_7 wyliczany jest oddzielny parametr trudności dla chłopców i dziewcząt.

```{r, cache = TRUE}
czyt_mod0 = tam.mml(czyt_r[, it_czyt], irtmodel = "PCM",
                   formulaY = ~ kobieta,
                   dataY = czyt_r[, "kobieta", drop = FALSE],
                   control = list(increment.factor = 1.01,
                                  progress = FALSE))
```


```{r, results = "hide"}
# dopasowanie zadań
czyt_fit0 = tam.fit(czyt_mod0)$itemfit

# scalenie oszacowań parametrów i dopasowania
czyt_mod0$xsi$parameter = rownames(czyt_mod0$xsi)
czyt_mod0_fit = merge(czyt_mod0$xsi, czyt_fit0)
```

```{r}
round_df(czyt_mod0_fit[, grep("param|xsi|fit$", names(czyt_mod0_fit))], 3)
```

Wykres dla miar dopasowania.

```{r, fig.keep = 'last'}
fitplot(czyt_mod0_fit)
```

```{r, results = "hide", fig.keep = "last", dev.args = list(pointsize = 8)}
plot(czyt_mod0, grep("KCA_5", czyt_mod0$item$item), ngroups = 7,
     type = "items", export = FALSE, package = "graphics")
```



