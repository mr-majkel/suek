---
title: "Analiza Rascha dla testu matematycznego TOS6"
author: "Michał Modzelewski"
csl: apa.csl
output:
  pdf_document:
    toc: no
  html_document:
    css: moj_styl.css
    fig_caption: yes
  word_document: default
bibliography: Rasch.bib
---

``` {r include = FALSE, cache = FALSE}

wd = getwd()
wd_len = sapply(strsplit(wd, "/"), length)
wd = paste(sapply(strsplit(wd, "/"), "[", 1:(wd_len - 1)), collapse = "/")
setwd(wd)


options("stringsAsFactors" = FALSE)
options("scipen" = 7)
options(width = 80)

library(TAM)
library(ggplot2)
library(reshape2)
# library(xtable)
library(plyr)

source("skrypty\\pomocnicze\\difWang.R")
source("skrypty\\pomocnicze\\sumPart.R")

# wczytaj dane
load("bazy zmien/bazy_mat.RData")

```

# O analizie
W niniejszym dokumencie opisane są analizy psychometryczne przeprowadzone dla testu matematycznego TOS6. Celem analiz jest:

1. Określenie, na ile zadania wchodzące w skład testu zachowują się zgodnie z przewidywaniami modelu Rascha [-@rasch_probabilistic_1980]. W tym celu przewidziano następujące kroki:
    a. Sprawdzenie ogólnego dopasowania zadań, w tym uporządkowania kategorii dla zadań wielokategorialnych.
    b. Sprawdzenie występowania efektu DIF ze względu na wersję testu.
    c. Sprawdzenie występowania efektu DIF ze względu na płeć.
2. Selekcja zadań najlepiej dopasowanych oraz ewentualna modyfikacja skal oceny (w przypadku zadań wielokategorialnych).
3. Wyliczenie oszacowań poziomu umiejętności dla uczniów na wyselekcjonowanym zbiorze zadań.

Analizy zostały przeprowadzone z wykorzystaniem środowiska R [@r_core_team_r:_2014] w wersji `r paste(R.Version()$major, R.Version()$minor, sep = ".")`. Głównym pakietem wykorzystanym do analiz jest pakiet `TAM` (`r paste0("ver.", packageVersion("TAM"))`).

Analizowane dane pochodzą z VII etapu *Badania szkolnych uwarunkowań efektywności kształcenia*. Testy rozwiązało łącznie `r nrow(mat_all)` uczniów. Uczniowie ci w roku szkolnym 2013/2014 uczyli się w `r length(unique(mat_all$ID_szk))` szkołach podstawowych. Zastosowane modele nie biorą niestety tego pogrupowania pod uwagę, a przez to znacznie nie doszacowują wielkość błędów standardowych. Przy interpretacji wyników trzeba mieć to na uwadze.

Do analiz z wykorzystaniem pakietu `TAM` potrzebne są dwa zbiory. Do analizy IRT potrzebne są dane zawierające wartości przekodowane - 0 odpowiada błędnym odpowiedziom, 1, 2,..., k - kolejnym poziomom wykonania, a systematyczne braki danych oznaczone są jako `NA`.

Do analizy KTT - pozwalającej m.in. na ocenę działania dystraktorów w zadaniach zamkniętych - potrzebne są z kolei zbiory surowe (zawierające informacje o wybranych przez ucznia odpowiedziach lub przyznanych kodach).

Poniżej przedstawiono fragmenty zbiorów danych wykorzystanych w analizach.

```{r}
# zbiór surowych danych
head(mat_all[, 1:10])
```

```{r}
# zbiór danych rekodowanych
head(mat_all_r[, 1:10])
```

Każdy wiersz odpowiada jednemu uczniowi. Na początku zbioru znajdują się zmienne identyfikujące i opisowe. Na dalszych miejscach znajdują się zmienne odpowiadające kolejnym zadaniom w teście. W skład tej grupy zmiennych wchodzą zadania z wersji A i B testu oraz zadania kotwiczące. Nazwy zmiennych kotwiczących powstały poprzez dodanie przedrostka "K" do nazwy zadania kotwiczącego w wersji A (np. `r paste0("K", kotw[1, 1])`). Na potrzeby analiz IRT kody '9' (brak odpowiedzi) były traktowane jako odpowiedzi błędne, chyba że stanowiły serię opuszczeń pod koniec zeszytu. W takim przypadku, podczas estymacji parametrów zadań (ale nie oszacowania poziomów umiejętności uczniów), seria braków odpowiedzi była traktowana jako systemtatyczny brak danych (`NA`), z wyłączeniem pierwszej "9" z serii.

## Krótko o teście

Test umiejętności matematycznych TOS6 składa się z dwóch wersji (A i B), po 25 zadań każda. Część zadań, tzw. zadania kotwiczące, jest taka sama dla obu wersji, pozostałe zadania są unikalne dla wersji. Każdy uczeń rozwiązywał tylko jedną wersję testu. Poniżej znajduje się tabela informująca o tym, które zadania w wersji A odpowiadają zadaniom w wersji B.

``` {r results='asis', echo = FALSE}
# print(xtable(kotw, "Tabela 1. Zadania kotwiczące w podziale na wersje.",
#              align = "ccc"),
#       type = "html", include.rownames = FALSE)
knitr::kable(kotw, row.names = FALSE,
             caption = "Zadania kotwiczące w podziale na wersje")
```

W teście znajdują się zarówno zadania zamknięte jak i otwarte. Zdecydowana większość zadań jest oceniania dychotomicznie. Do ich analizy został wykorzystany prosty model logistyczny (*simple logistic model*, SLM). Wybrane zadania otwarte są jednak oceniane na skali 0-1-2. Do ich analizy zastosowano model *partial credit model* (PCM). Do analizy DIF wykorzystano wieloaspektowy model Rascha (*Mulit-faceted Rasch model*, MFR). Pakiet `TAM` umożliwia elastyczne specyfikowanie tych modeli, wykorzystując uogólnioną formę modelu Rascha opisaną w [@adams_multidimensional_1997]. Do estymacji tego modelu wykorzystywana jest metoda brzegowej najwyższej wiarygodności (*marginal maximum likelihood*, MML). Metoda ta wymaga założenia o kształcie rozkładu umiejętności w badanej populacji. W pakiecie `TAM` rozkład ten przybliżany jest za pomocą rozkładu normalnego (o estymowanej średniej i odchyleniu standardowym).

# Ogólne sprawdzenie dopasowania danych do modelu Rascha

Skalowanie zaczniemy od próby dopasowania danych do modelu Rascha. W związku z tym, że analizy chcemy wykonać tylko na podzbiorze zadań (zadania unikalne dla wersji *plus* zadania kotwiczące), potrzebujemy określić, które zmienne chcemy uwzględnić w analizach.

```{r}
# nazwy wszystkich zadań w teście
items_all = grep("MA|MB", names(mat_all_r), value = TRUE)

# nazwy wszystkich itemów do skalowania
items1 = items_all[!(items_all %in% kotw)]
items1
```

Możemy już wyestymować pierwszy model. Do tego celu wykorzystamy funkcję `tam.mml()`.

``` {r, echo = FALSE, results = 'hide', cache = TRUE}
# przygotowanie macierzy do wyestymowania modelu
des1 = designMatrices.mfr2(resp = mat_all_r[, items1],
                            formula = ~ item + item:step)
resp1 = des1$gresp$gresp.noStep

# macierz A
A = des1$A$A.3d
# macierz B
B = des1$B$B.3d
# parametry nieestymowalne (np. step 2, dla zadań kodowanych 0-1)
xsi.elim = des1$xsi.elim

A1 = A[, , -xsi.elim[, 2]]
mod0 = tam.mml(resp1, A = A1, B = B,
               control = list(QMC = FALSE))
```

Tak wyspecyfikowany model pozwala nam sprawdzić, na ile niemodyfikowane dane zachowują się zgodnie z przewidywaniami modelu Rascha. Rzućmy zatem okiem na podsumowanie modelu (wszystkie pliki z podsumowaniem modelu zapisane są w folderze "modele").

```{r, echo = 2, results = 'hide'}
setwd(wd)
summary(mod0, "modele/mod0")
```

W związku z tym, że podsumowanie modelu jest dosyć obszerne (zajmuje ponad dwie strony!), w niniejszym raporcie będziemy wczytywać tylko wybrane jego części. Warto jednak omówić krótko całą jego strukturę.

W pierwszej opisane są informacje dotyczące wersji pakietu, środowiska R oraz czasu wykonania analizy. Ta część kończy się informacją o rodzaju wyestymowanego modelu (1PL, czyli model Rascha).

```{r, echo = FALSE}
setwd(wd)
sumPart("modele/mod0__SUMMARY.Rout", 1)
```

Kolejna część zawiera informacje podsumowujące wykonaną analizę - m.in. liczbę wyestymowanych parametrów modelu (`r mod0$ic$Npars`), liczbę iteracji (`r mod0$iter`), a także ostateczną wartość funkcji wiarygodności (*log likelihood* i *deviance*, odpowiednio `r round(mod0$ic$deviance/-2, 2)` i `r round(mod0$ic$deviance, 1)`).

```{r, echo = FALSE}
setwd(wd)
sumPart("modele/mod0__SUMMARY.Rout", 2)
```

W kolejnej zawarto wartość współczynnika rzetelności EAP/PV, czyli stosunku wariancji cechy wyliczonej na podstawie oszacowań EAP, do wariancji wyliczonej z PV.

```{r, echo = FALSE}
setwd(wd)
sumPart("modele/mod0__SUMMARY.Rout", 3)
```

W kolejnych dwóch opisane są związki pomiędzy zmiennymi wykorzystanymi w regresji latentnej (czyli warunkowaniu). W związku z tym, że model ten nie zawierał regresji latentnej, mamy informację tylko o wariancji i odchyleniu standardowym umiejętności matematycznych.

```{r, echo = FALSE}
setwd(wd)
sumPart("modele/mod0__SUMMARY.Rout", c(4, 5))
```

W przedostatniej części zamieszczone są współczynniki regresji latentnej. Widzimy, że średnia dla umiejętności matematycznych została ustalona na zero.

```{r, echo = FALSE}
setwd(wd)
sumPart("modele/mod0__SUMMARY.Rout", 6)
```

Ta ostatnia informacja jest szczególnie ważna w kontekście analizy oszacowań parametrów zadań. Trudności zadań należy bowiem interpretować w odniesieniu do średniej. I tak, zadanie o trudności 0, to zadanie, dla którego prawdopodobieństwo poprawnej odpowiedzi ucznia o przeciętnym poziomie umiejętności wynosi 50%. W kolejnej części przedstawione są wyestymowane parametry zadań (w części zatytułowanej "Item Parameters Xsi"). Oprócz oszacowań trudności zadań podane są również ich błędy standardowe. Warto jednak informacje te analizować w uzupełnieniu o miary dopasowania. Pakiet `TAM` pozwala na wyliczenie dwóch klasycznych statystyk dopasowania - *infit* i *outfit*.

```{r, echo = FALSE}
# wyliczenie miar dopasowania
fit0 = tam.fit(mod0, progress = FALSE)$itemfit

# scalenie zbiorów danych
mod0$xsi$parameter = rownames(mod0$xsi)
mod0_fit = merge(mod0$xsi, fit0)

# niedopasowane zadania <0,8 lub >1,2
out0 = mod0_fit[(mod0_fit[, 4] < 0.8) | (mod0_fit[, 4] > 1.2), "parameter"]
in0 = mod0_fit[(mod0_fit[, 8] < 0.8) | (mod0_fit[, 8] > 1.2), "parameter"]

round_df = function(df, ...) {
    col_class = sapply(df, class)
    col_num = names(grep("numeric", col_class, value = TRUE))
    df[, col_num] = round(df[, col_num], ...)
    df
  }

round_df(mod0_fit[, c(1:6, 8:10)], 3)
```

Trzymając się zwyczajowych kryteriów dopuszczalnego dopasowania, tj. przedziału wartości <0,8; 1,2>, prawie wszystkie zadania, na pierwszy rzut oka, są dobrze dopasowane. Jedynie zadania `r out0` posiadają wartości statystyki *outfit* wykraczające poza ten zakres.

```{r, echo = FALSE, fig.cap= "Wykres skrzynkowy dla miar dopasowania zadań w teście matematycznym TOS6"}
# wykres pudełkowy dla miar dopasowania
mod0_md = melt(mod0_fit, "parameter")
mod0_fit_stat = mod0_md[grep("fit$", mod0_md$variable), ]
boxy = ggplot(mod0_fit_stat,
              aes(x = variable, y = value)) + ylim(0.5, 1.6) + geom_boxplot() +
       geom_point(data = mod0_fit_stat[mod0_fit_stat$value > 1.2,]) +
       geom_text(aes(label = parameter),
                 data = mod0_fit_stat[mod0_fit_stat$value > 1.2,], hjust = -0.1)
boxy
```

Przyjrzyjmy się im bliżej. Zadanie `r out0[1]` ("Jaką część makulatury zebranej przez uczniów klas IV-VI stanowi makulatura zebrana przez uczniów klas szóstych?") dotyczy umiejętności oszacowania odsetka. Zadanie `r out0[2]` ("Która z figur nie występuje na tym rysunku?") geometrii. Poniżej znajdują się wykresy z krzywą dla przewidywanego wyniku dla tych zadań z naniesioną krzywą empiryczną.

```{r, results = "hide", echo = FALSE, fig.cap = c("Krzywa przewidywanego wyniku w zależności od poziomu umiejętności dla zad. MA_20 (lewy) i MB_25 (prawy)"), fig.keep = 'last', dev.args = list(pointsize = 9)}
# wykresy ESC dla zadań
layout(t(1:2))
plot(mod0, match(out0[1], mod0$item$item), ngroups = 10, export = FALSE,
     observed = TRUE)
plot(mod0, match(out0[2], mod0$item$item), ngroups = 10, export = FALSE,
      observed = TRUE)
```

Widzimy, że zadania słabiej różnicują uczniów niż by to wynikało z modelu Rascha. Oba zadania są zadaniami wielokrotnego wyboru. Być może trochę światła na ich funkcjonowanie rzuci analiza dystraktorów. Poniżej zamieszczone są wykresy z krzywymi empirycznymi dla wszystkich kodów obecnych w bazie. Odpowiedziom A, B, C, D przyporządkowane zostały kody, odpowiednio, 1, 2, 3 i 4.

```{r, results = "hide", echo = FALSE, fig.cap ="Krzywe empiryczne dla kategorii zadań XXX"}

# analiza KTT dla dwóch zadań
# wyliczenie pv dla modelu
mod0_pv = tam.pv(mod0)$pv

# wyliczenie statystyk KTT
ctt0 = tam.ctt(mat_all[, items1], pvscores = mod0_pv[, -1])

# wykresy z krzywmi empirycznymi
# layout(t(1:2))
plotctt(mat_all[, out0[1], drop = FALSE], theta = mod0_pv[, 2], Ncuts = 8)
plotctt(mat_all[, out0[2], drop = FALSE], theta = mod0_pv[, 2], Ncuts = 8)

```


Dla zadania `r out0[1]` poprawną odpowiedzią jest odpowiedź C ("0,428...", kod 3), natomiast dla zadania `r out0[2]` - B ("trójkąt równoboczny", kod 2). Poziom umiejętności (estymowany za pomocą PV) został podzielona na 8 równolicznych przedziałów. Dla tak określonych grup wyników wyliczone zostały odsetki uczniów, którzy otrzymali poszczególne kody w zadaniu. Dla obu zadań można wskazać dystraktory, które mają w szerokim zakresie badanej umiejętności niemalejące prawdopodobieństwo wyboru (dopiero w ostatniej grupie wyników zaczyna spadać). I tak, dla zadania `r out0[1]` taką niewzruszoną konkurencję dla poprawnej odpowiedzi stanowi odpowiedź A ("0,333...", kod 1), natomiast dla zadania `r out0[2]` to odpowiedź C ("trapez prostokątny", kod 3) oraz odpowiedź A ("romb", kod 1).

Po uzupełnieniu analizy ilościowej zadań analizą treściową postanowiono nie uwzględniać zadania MB\_25 przy oszacowaniu wyników (zadanie MA\_20 pozostawiono). Bardzo wysoka, wbrew oczekiwaniom teoretycznym, popularność odpwiedzi C każe przypuszczać, że pojęcie trapezu prostokoątnego nie jest na tyle znane uczniom, by uznać je za trafne zadanie. Obserwacja ta współgra z faktem, że w *Podstawie programowej* (zarówno "starej" jak i "nowej") dla drugiego etapu edukacyjnego nie wyrózniono takiego pojęcia (mowa jest tylko o "trapezach"). Z tego też względu sugeruje się, nieuwzględnianie tego zadania w następnych zastosowaniach TOS6.

# Model 2 (bez zad. MB_25)

Na potrzeby dalszych analiz policzono nowy model, nieuwzględniający zadania MB_25.

```{r, echo = FALSE, results = "hide", cache = TRUE}
############ model 2
items2 = grep("^MB_25", items1, value = TRUE, invert = TRUE)
# przygotowanie macierzy do wyestymowania modelu
des2 = designMatrices.mfr2(resp = mat_all_r[, items2],
                            formula = ~ item + item:step)
resp2 = des2$gresp$gresp.noStep

# macierz A
A = des2$A$A.3d
# macierz B
B = des2$B$B.3d
# parametry nieestymowalne (np. step 2, dla zadań kodowanych 0-1)
xsi.elim = des2$xsi.elim

A1 = A[, , -xsi.elim[, 2]]
mod2 = tam.mml(resp2, A = A1, B = B,
               control = list(QMC = FALSE))

setwd(wd)
summary(mod2, "modele/mod2")
```

```{r, echo = FALSE}
setwd(wd)
sumPart("modele/mod2__SUMMARY.Rout", c(2:4))
```

## Dopasowanie zadań do modelu Rascha

Dopasowanie zadań zaadniczo się nie zmieniło. Zad MA\_20 wciąż wykazuje niższą niż przewidywana dyskryminację.

```{r, echo = FALSE}
# scalenie zbiorów danych
mod2$xsi$parameter = rownames(mod2$xsi)
mod2_fit = merge(mod2$xsi, fit0)

# niedopasowane zadania <0,8 lub >1,2
out2 = mod2_fit[(mod2_fit[, 4] < 0.8) | (mod2_fit[, 4] > 1.2), "parameter"]
in2 = mod2_fit[(mod2_fit[, 8] < 0.8) | (mod2_fit[, 8] > 1.2), "parameter"]

round_df(mod2_fit[, c(1:6, 8:10)], 3)
```

```{r, echo = FALSE, fig.cap= "Wykres skrzynkowy dla miar dopasowania zadań w teście matematycznym TOS6"}
# wykres pudełkowy dla miar dopasowania
mod2_md = melt(mod2_fit, "parameter")
mod2_fit_stat = mod2_md[grep("fit$", mod2_md$variable), ]
boxy2 = ggplot(mod2_fit_stat,
              aes(x = variable, y = value)) + ylim(0.5, 1.6) + 
       geom_boxplot() +
       geom_point(data = mod2_fit_stat[(mod2_fit_stat$value > 1.2) |
                                         (mod2_fit_stat$value < 0.8),]) +
       geom_text(aes(label = parameter),
                 data = mod2_fit_stat[(mod2_fit_stat$value > 1.2) |
                                         (mod2_fit_stat$value < 0.8),],
                 hjust = -0.1) +
       geom_hline(aes(yintercept = c(0.8, 1.2)), linetype = 2)
boxy2
```

## Uporządkowanie kategorii dla zadań wielokategorialnych

Dla zadań wielokategorialnych (ocenianych na skalach dłuższych niż 0-1) sprawdzono uporządkowanie poszczególnych progów wykonania zadania. W teście matematycznym są `r length(grep("step1", rownames(mod0$xsi)))` zadania oceniane na skali 0-1-2. Poniżej zaprezentowane są wykresy z krzywymi informacyjnymi dla tych zadań.

```{r, echo = FALSE, results = "hide", fig.keep = 'all', dev.args = list(pointsize = 9)}
# icc dla zadań wielokategorialnych
plot(mod2, grep("KMA_10", mod2$item$item),
     type = "items", export = FALSE)
plot(mod2, grep("KMA_22", mod2$item$item),
     type = "items", export = FALSE)

```

Dla obu zadań kategoria 1 (na wykresie Cat2) dla żadnego zakresu umiejętności nie jest kategorią modalną (najczęściej wybieraną). Co za tym idzie, oszacowane parametry $\delta$, czyli punkty na skali umiejętności, dla których przecinają się krzywe informacyjne dla kolejnych kategorii punktowych (0 i 1, 1 i 2), są nieuporządkowane. Łatwiejsze jest "przejście" między kategorią 1 i 2 niż pomiedzy 0 i 1.

Sytuację te można także zobrazować za pomocą tzw. progów Thurstone'a (*Thurstonian tresholds*). Progi te odpowiadają pozycji na skali umiejętności, dla których wartość funkcji prawdopodobieństwa uzyskania danej kategorii lub wyższej wynosi 50%. W przypadku zadania ocenianego na skali 0-1-2 analizowane są dwie krzywe: jedna przedstawiąjąca zależność pomiędzy umiejętnością a prawdopodobieństwem uzyskania kategorii 1 lub 2, a druga - uzyskania kategorii 2. W omawianej sytuacji kolejne progi Thurstone'a są ulokowane blisko siebie.

```{r, echo = FALSE}
# tresholdy dla mod0
mod2_tt = tam.threshold(mod2)
mod2_tt[grep("KMA_10|KMA_22", rownames(mod2_tt)),]
# ttc dla zadań wielokategorialnych
# TODO


```

Takie wyniki oznaczają, że bardzo mały odsetek uczniów uzyskał za te zadania 1 punkt. Można to odczytywać jako sygnał na rzecz redundancji kategorii 1 w kluczu. Z drugiej jednak strony, dobre dopasowanie zadań wielokategrialnych do przewidywań modelu nie wymusza działań naprawczych. Dodatkowo, lektura odpowiednich zapisów klucza kodowego nie rodzi podejrzeń co do ich zrozumiałości i trafności. Po dyskusji w zespole postanowiono nie modyfikować klucza. 

## Analiza zróżnicowanego funkcjonowania zadania (DIF) ze względu na wersję

W teście matematycznym znajduje się `r nrow(kotw)` zadań kotwiczących. Poprzednie skalowanie bazowało na założeniu, że zadania te funkcjonują tak samo w obu wersjach testu. W tej części raportu założenie to zostanie sprawdzone. Do tego celu wyestymowano model, w którym dopuszczono zróżnicowane oszacowanie parametrów zadań w obu wersjach testu.

```{r, echo = FALSE, results = "hide", cache = TRUE}
# sprawdzenie międzygrupowej inwariantności (DIF na wersję)
formulaA_difwer = ~ item + item:step + wersja*item + wersja:item:step
# nazwy itemów kotwiczących
# items_kotw = paste0("K", kotw[, 1])
head(mat_all_r)
# policzenie modelu multi-faceted rasch, pełna wariantność parametrów
mod3 = tam.mml.mfr(mat_all_r[, items2],
                   facets = mat_all_r[, "wersja", drop = FALSE],
                   formulaA =formulaA_difwer,
                   control = list(QMC = FALSE,
                                  increment.factor=1.01,
                                  fac.oldxsi=.05,
                                  delete.red.items = TRUE))
setwd(wd)
summary(mod3, "modele/mod3")
```

```{r, echo = FALSE}
setwd(wd)
sumPart("modele/mod3__SUMMARY.Rout", c(2:4))
```

Analizie poddane będą jednak tylko zadania kotwiczące i oszacowane różnice w trudności ze względu na wersję. Otrzymane oszacowania należy pomnożyć przez dwa, dla otrzymania całkowitej różnicy w oszacowaniu trudności zadań pomiędzy wersjami.

```{r, echo = FALSE}
round(mod3$xsi[grep("^K.*A$|KMA_10:wersjaA:step1|KMA_22:wersjaA:step1",
                    rownames(mod3$xsi)), ], 3)
```

Dla większości zadań efekty związane z różnicami funkcjonowania pomiędzy wersjami są niewielkie. Tylko zadanie KMA\_24 i oszacowanie dla progów dla zadania KMA\_22 wykazują róźnicę w trudności pomiędzy wersjami większą od 0,2 logita (odpowiednio, na korzyść wersji A i wersji B). Zadanie te są jednak dosyć trudne i duża różnica w logitach nie przekłada się na duż różnicę prawdopodobieństwa odpowiedzi.

```{r, echo = FALSE, results = "hide", warning = FALSE}

items_kotw = paste0("K", kotw[, 1])

mod3_pv = tam.pv(mod3)$pv

# KTT dla mfr, dif na wersję
ctt3 = tam.ctt(mat_all[, items_kotw], pvscores = mod3_pv[, -1],
               group = mat_all$wersja, progress = FALSE)

print_ctt = function(ctt_df, item, group = 1) {
    ctt_col = grep("item$|group|PV|N|Categ|Freq", names(ctt_df))
    ctt_df[(ctt_df$item == item) & (ctt_df$group == group), ctt_col]
  }

```

```{r, echo = FALSE, warning = FALSE}
for (ik in c("KMA_22", "KMA_24")) {
    cat(paste0("\nZad. ", ik, "\n"))
    print(round_df(print_ctt(ctt3, ik, "A"), 3))
    print(round_df(print_ctt(ctt3, ik, "B"), 3))
  }

```

Różnice w odsetkach uczniów uzyskujących poszczególne kategorie pomiędzy wersjami testu są minimalne (wahają się w granicach 2-3 pkt. proc.). W związku z tym, można uznać, że zadania kotwiczące dobrze spełniaja swoją funkcję.

##  Analiza zróżnicowanego funkcjonowania zadania (DIF) ze względu na płeć

Ważnym aspektem każdego pomiaru jest inwariantność narzędzia ze względu na różne cechy badanych obiektów. W przypadku testów osiągnięć szkolnych, wyniki uczniów często analizowane są w podziale na płeć. Oszacowanie różnic pomiędzy wynikami chłopców i dziewczynek jest możliwe tylko wtedy, gdy test, którego wyniki analizujemy, nie jest systematycznie obciążony na korzyść którejś z płci ponad to, co możemy przypisać faktycznym różnicom w poziomie umiejętności.

Na potrzeby analiz DIF ze względu na płeć policzono model, w którym dla każdego zadania wyliczono różnice w oszacowaniu trudności po uwzględnieniu średniej różnicy w poziomach umiejętności między chłopcami i dziewczynkami.

```{r, echo = FALSE, results = "hide"}
# sprawdzenie międzygrupowej inwariantności (DIF na wersję)
formulaA_difplec = ~ item + item:step + kobieta*item + kobieta:item:step
# nazwy itemów kotwiczących
# items_kotw = paste0("K", kotw[, 1])
head(mat_all_r)
# policzenie modelu multi-faceted rasch, pełna wariantność parametrów
mod4 = tam.mml.mfr(mat_all_r[, items2],
                   facets = mat_all_r[, "kobieta", drop = FALSE],
                   formulaA = formulaA_difplec,
                   control = list(QMC = FALSE,
                                  increment.factor=1.01,
                                  fac.oldxsi=.05,
                                  delete.red.items = TRUE))
setwd(wd)
summary(mod4, "modele/mod4")
```

```{r, echo = FALSE}
setwd(wd)
sumPart("modele/mod4__SUMMARY.Rout", c(2:4))
```

Poniżej przedstawiono oszacowania różnic w trudności ze względu na płeć (chłopcy są grupą odniesienia).

```{r, echo = FALSE}
dif_ind = grep("kobieta0$|KMA_22:kobieta0:step1|KMA_10:kobieta0:step1",
               rownames(mod4$xsi))
dif_xsi = round(mod4$xsi[dif_ind, ], 3)
```

Swoja uwagę skupimy na zadaniach, które prezentują całkowity efekt różnicy pomiędzy płciami większy od 0,4 logita.

```{r, echo = FALSE}
dif_its = rownames(dif_xsi)[abs(dif_xsi$xsi * 2) > 0.4]
items_dif = sapply(strsplit(dif_its, ":"), "[", 1)
dif_xsi[dif_its, ]
```

Jak te różnice przekładaja się na odsetki poszczególnych kategorii (grupa 0?

```{r, results = "hide", warning = FALSE}
mod4_pv = tam.pv(mod4)$pv

# KTT dla mfr, dif na wersję
ctt4 = tam.ctt(mat_all[, items_dif], pvscores = mod4_pv[, -1],
               group = mat_all$plec, progress = FALSE)
```

```{r, echo = FALSE, warning = FALSE}
for (ik in items_dif) {
    cat(paste0("\nZad. ", ik, "\n"))
    print(round_df(print_ctt(ctt4, ik, "M"), 3))
    print(round_df(print_ctt(ctt4, ik, "K"), 3))
  }

```

Dla opisania zadania jako funkcjonującego w różny sposób dla płci przyjęto konieczność wystapienia dwóch warunków:

- zaobserwowania wysokiej różnicy w oszacowaniach trudności zadań dla płci
- możliwości przypisania różnic w szansach poradzenia sobie z zadaniem specyficznym uwarunkowaniom płci (więcej treningu, specyficzna wiedza).

Po analizie treściowej zadań, tylko zadanie MA\_7 ("Żaglówka znajduje się w odległości 30 m od linii mety i płynie z prędkością 4 m/s. Po jakim czasie znajdzie się ona na mecie?") zostało uznane jako zadanie z DIF na płeć. Zadanie to dotyczy przeliczania prędkości, drogi oraz czasu. Istnieje podejrzenie, że chłopcy przechodzą swoisty trening w takich obliczeniach ze względu na fakt, że częściej w obszarze zainteresowań chłopców znajdują się samochody i ich osiągi.

Na potrzeby wyliczania wyników uczniów, parametr trudności dla zadania MA\_7 będzie oszacowywany oddzielnie dla płci. W efekcie zadanie to będzie łatwiejsze dla chłopców niż dla dziewczynek.

```{r, echo = FALSE}
# zmodyfikowanie baz

# baza nierekodowana
mat_all2 = mat_all
mat_all2$MA_7k = mat_all$MA_7
mat_all2$MA_7m = mat_all$MA_7

mat_all2[mat_all2$plec == "M", "MA_7k"] = NA
mat_all2[mat_all2$plec == "K", "MA_7m"] = NA

# baza rekodowana
mat_all_r2 = mat_all_r
mat_all_r2$MA_7k = mat_all_r$MA_7
mat_all_r2$MA_7m = mat_all_r$MA_7

mat_all_r2[mat_all_r2$plec == "M", "MA_7k"] = NA
mat_all_r2[mat_all_r2$plec == "K", "MA_7m"] = NA


```

# Model ostateczny, wyliczenie wyników uczniów

W modelu tym nie wuzględnia się zadania MB\_25, a trudność zadania MA\_7 jest wyliczana oddzielnie dla chłopców i dziewczynek.

```{r, echo = FALSE, results = "hide", cache = TRUE}
############ model 5
# zadania do uwzględnienia w ostatecznym modelu
items3a = items2[-grep("MA_7", items2)]
items3 = c(items3a, "MA_7k", "MA_7m")

mod5 = tam.mml(mat_all_r2[, items3],
               formulaY = ~ kobieta,
               dataY = mat_all_r2[, "kobieta", drop = FALSE],
               control = list(QMC = FALSE))

setwd(wd)
summary(mod5, "modele/mod5")
```

```{r, echo = FALSE}
setwd(wd)
sumPart("modele/mod5__SUMMARY.Rout", c(2:4))
```

Wyliczanie wyników oodbywalo sie w kilku krokach.

1. Wyekstrahowanie parametrów zadań z modelu ostatecznego.

```{r, echo = FALSE} 
### Krok pierwszy: wyekstrahowanie macierzy z oszacowaniami z mod_ost
xsi_fixed = cbind(1:length(mod5$xsi$xsi),
                  mod5$xsi$xsi)
```

2. Przekodowanie zadań nieosiągniętych (*not reached*) na odpowiedzi błędne.

```{r, echo = FALSE, results = "hide"}
### Krok drugi: przygotowanie baz bez NA pod koniec zeszytów

# sprawdzenie, czy w case'y są tak samo poukladane w bazie (powinny być,
# ale...;) )
any(mat_all2$ID_ucz != mat_all_r2$ID_ucz)
# powinno być FALSE

# głównym problemem jest istnienie NA pod koniec zeszytów w bazie mat_all_r
# podmieńmy je na zera
# prosta funkcja do rekodowania "zwrotnego"
# funkcja niepodmienia eNek w zadaniach, które nie występują w bazie
# nierekodowanej (zostawia je jak są), dlatego warto rozpłciowić zadania w bazie
# nierekodowanej w taki sam sposób, jak w rekodowanej.

recode_back = function(df_r, df, item = "^[KC]", code = "N") {
  zad_df_r = df_r[, grep(item, names(df_r))]
  zad_df = df[, grep(item, names(df))]
  
  zad_df_r2 = as.data.frame(lapply(names(zad_df_r), function(nm) {
    if(nm %in% names(zad_df)) {
      zad_df_r[which(zad_df[, nm] == code), nm] = 0      
    }
    zad_df_r[, nm]
    
  }), stringsAsFactors = FALSE)
  
  df_r[, grep(item, names(df_r))] = zad_df_r2
  df_r
}

mat_all_r3 = recode_back(mat_all_r2, mat_all2, item = "^[KM]")
```

3. Policzenie średnich klasowych na podstawie oszacowań EAP z modelu z regresją latentną na płeć i z parametrami zadań z modelu ostatecznego.

```{r, echo = FALSE, results = 'hide'}
### Krok trzeci: policzenie średnich klasowych
mod_mean = tam.mml(mat_all_r3[, items3], xsi.fixed = xsi_fixed,
               formulaY = ~ kobieta,
               dataY = mat_all_r3[, "kobieta", drop = FALSE])

# dołączenie oszacowań do uczniów z informacją o klasie i szkole
osz_ucz = data.frame(mat_all_r3[, grep("ID_ucz|ID_szk|oddz_6|kobieta",
                                        names(mat_all_r3))],
                     wyn = mod_mean$person$EAP) 
# policzenie średniej dla klas
osz_kl_mn = plyr::ddply(osz_ucz, c("ID_szk", "oddz_6"),
                         summarize, srednia_kl = mean(wyn))
# dodanie średniej do zbioru danych
osz_ucz2 = merge(osz_ucz, osz_kl_mn, all.x = TRUE)
```

4. Policzenie wyników (EAP oraz 5 PV) w modelu z regresją latentną na płeć i średnią klasową oraz z parametrami zadań z modelu ostatecznego.

```{r, echo = FALSE, results = "hide"}
### Krok czwarty: policzenie wyników z uwzględnieniem średniej klasowej
mod_ost_mn = tam.mml(mat_all_r3[, items3], xsi.fixed = xsi_fixed,
                 formulaY = ~ kobieta + srednia_kl,
                 dataY = osz_ucz2[match(osz_ucz2$ID_ucz, mat_all_r3$ID_ucz), ],
                 pid = mat_all_r3$ID_ucz)

# policzenie 5 PV
pv_ucz = tam.pv(mod_ost_mn, 5)$pv

# dołączenie PV do wyników EAP i bł.st.
wyn_ucz = merge(mod_ost_mn$person, pv_ucz, all.x = TRUE)
wyn_ucz = wyn_ucz[, -grep("case|pweight", names(wyn_ucz))]

# zmiana nazw zmiennych: EAPy
zmod_EAP = paste0(names(wyn_ucz)[grep("EAP", names(wyn_ucz))], "_m")
names(wyn_ucz)[grep("EAP", names(wyn_ucz))] = zmod_EAP

# zmiana nazw zmiennych: PV
zmod_PV = gsub(".Dim1", "_m", names(wyn_ucz)[grep("PV", names(wyn_ucz))])
names(wyn_ucz)[grep("PV", names(wyn_ucz))] = zmod_PV

# zapisanie zbioru
# write.csv2(wyn_ucz, "bazy zmien/TOS6_wyniki_mat.csv", row.names = FALSE)
```

Histogram wyników (EAP).

```{r, echo = FALSE}
hist(wyn_ucz$EAP_m, breaks = 30, freq = FALSE, xlab = "EAP", main = "")
```

Wykres rozrzutu dla błędu oszacowania w zależności od EAP.

```{r, echo = FALSE}
plot(wyn_ucz$EAP_m, wyn_ucz$SD.EAP_m, xlab = "EAP", ylab = "SD",
     ylim = c(0.3, 0.7), xlim = c(-3, 3), col = rgb(0, 0, 0, 0.3))
```


# Podsumowanie uwag do dalszych zastosowań testu

1. Usunąć zad. MB\_25 (nietrafne).
2. Trudność zadania MA\_7 wyliczana oddzielnie dla chłopców i dziewczynek.

# Załącznik 1. Parametry modelu ostatecznego

```{r, echo = FALSE}
# wyliczenie miar dopasowania
fit5 = tam.fit(mod5, progress = FALSE)$itemfit

# scalenie zbiorów danych
mod5$xsi$parameter = rownames(mod5$xsi)
mod5_fit = merge(mod5$xsi, fit5)

round_df(mod5_fit[, c(1:6, 8:10)], 4)
```

# Załącznik 2. Skrypt do wyliczenia ostatecznego modelu

```{r, eval = FALSE}
# wczytaj dane
load("bazy zmien/bazy_mat.RData")

# dodanie do bazy zadania rozpłciowionego MA_7
# baza nierekodowana
mat_all2 = mat_all
mat_all2$MA_7k = mat_all$MA_7
mat_all2$MA_7m = mat_all$MA_7

mat_all2[mat_all2$plec == "M", "MA_7k"] = NA
mat_all2[mat_all2$plec == "K", "MA_7m"] = NA

# baza rekodowana
mat_all_r2 = mat_all_r
mat_all_r2$MA_7k = mat_all_r$MA_7
mat_all_r2$MA_7m = mat_all_r$MA_7

mat_all_r2[mat_all_r2$plec == "M", "MA_7k"] = NA
mat_all_r2[mat_all_r2$plec == "K", "MA_7m"] = NA

# zadania do skalowania
items3 =  c("MA_1", "MA_2", "MA_3", "MA_5", "MA_11", "MA_17", "MA_19", "MA_20",
            "MA_21", "MA_25", "MB_1", "MB_2", "MB_3", "MB_5", "MB_10", "MB_11",
            "MB_15", "MB_19", "MB_20", "MB_21", "KMA_4", "KMA_6", "KMA_8",
            "KMA_9", "KMA_10", "KMA_12", "KMA_13", "KMA_14", "KMA_15", "KMA_16",
            "KMA_18", "KMA_22", "KMA_23", "KMA_24", "MA_7k", "MA_7m")

# policzenie modelu
mod5 = tam.mml(mat_all_r2[, items3],
               formulaY = ~ kobieta,
               dataY = mat_all_r2[, "kobieta", drop = FALSE],
               control = list(QMC = FALSE))

# wyliczenie miar dopasowania
fit5 = tam.fit(mod5, progress = FALSE)$itemfit

# scalenie zbiorów danych
mod5$xsi$parameter = rownames(mod5$xsi)
mod5_fit = merge(mod5$xsi, fit5)

# parametry i miary dopasowania
round_df(mod5_fit[, c(1:6, 8:10)], 4)

```

# Załącznik 3. Skrypt do wyliczenia wyników uczniów.

```{r, eval = FALSE}
# Zakłada się, że najpierw wyliczono model ostateczny znajdujący się w
# Załączniku 2.

### Krok pierwszy: wyekstrahowanie macierzy z oszacowaniami z mod5
xsi_fixed = cbind(1:length(mod5$xsi$xsi),
                  mod5$xsi$xsi)

### Krok drugi: przygotowanie baz bez NA pod koniec zeszytów

# sprawdzenie, czy w case'y są tak samo poukladane w bazie (powinny być,
# ale...;) )
any(mat_all2$ID_ucz != mat_all_r2$ID_ucz)
# powinno być FALSE

# głównym problemem jest istnienie NA pod koniec zeszytów w bazie mat_all_r
# podmieńmy je na zera
# prosta funkcja do rekodowania "zwrotnego"
# funkcja niepodmienia eNek w zadaniach, które nie występują w bazie
# nierekodowanej (zostawia je jak są), dlatego warto rozpłciowić zadania w bazie
# nierekodowanej w taki sam sposób, jak w rekodowanej.

recode_back = function(df_r, df, item = "^[KC]", code = "N") {
  zad_df_r = df_r[, grep(item, names(df_r))]
  zad_df = df[, grep(item, names(df))]
  
  zad_df_r2 = as.data.frame(lapply(names(zad_df_r), function(nm) {
    if(nm %in% names(zad_df)) {
      zad_df_r[which(zad_df[, nm] == code), nm] = 0      
    }
    zad_df_r[, nm]
    
  }), stringsAsFactors = FALSE)
  
  df_r[, grep(item, names(df_r))] = zad_df_r2
  df_r
}

mat_all_r3 = recode_back(mat_all_r2, mat_all2, item = "^[KM]")

### Krok trzeci: policzenie średnich klasowych
mod_mean = tam.mml(mat_all_r3[, items3], xsi.fixed = xsi_fixed,
               formulaY = ~ kobieta,
               dataY = mat_all_r3[, "kobieta", drop = FALSE])

# dołączenie oszacowań do uczniów z informacją o klasie i szkole
osz_ucz = data.frame(mat_all_r3[, grep("ID_ucz|ID_szk|oddz_6|kobieta",
                                        names(mat_all_r3))],
                     wyn = mod_mean$person$EAP) 
# policzenie średniej dla klas
osz_kl_mn = plyr::ddply(osz_ucz, c("ID_szk", "oddz_6"),
                         summarize, srednia_kl = mean(wyn))
# dodanie średniej do zbioru danych
osz_ucz2 = merge(osz_ucz, osz_kl_mn, all.x = TRUE)

### Krok czwarty: policzenie wyników z uwzględnieniem średniej klasowej
mod_ost_mn = tam.mml(mat_all_r3[, items3], xsi.fixed = xsi_fixed,
                 formulaY = ~ kobieta + srednia_kl,
                 dataY = osz_ucz2[match(osz_ucz2$ID_ucz, mat_all_r3$ID_ucz), ],
                 pid = mat_all_r3$ID_ucz)

# policzenie 5 PV
pv_ucz = tam.pv(mod_ost_mn, 5)$pv

# dołączenie PV do wyników EAP i bł.st.
wyn_ucz = merge(mod_ost_mn$person, pv_ucz, all.x = TRUE)
wyn_ucz = wyn_ucz[, -grep("case|pweight", names(wyn_ucz))]

# zmiana nazw zmiennych: EAPy
zmod_EAP = paste0(names(wyn_ucz)[grep("EAP", names(wyn_ucz))], "_m")
names(wyn_ucz)[grep("EAP", names(wyn_ucz))] = zmod_EAP

# zmiana nazw zmiennych: PV
zmod_PV = gsub(".Dim1", "_m", names(wyn_ucz)[grep("PV", names(wyn_ucz))])
names(wyn_ucz)[grep("PV", names(wyn_ucz))] = zmod_PV

# zapisanie zbioru
write.csv2(wyn_ucz, "bazy zmien/TOS6_wyniki_mat.csv", row.names = FALSE)

```


# Literatura cytowana
